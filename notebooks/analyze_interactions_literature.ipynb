{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "import openai\n",
    "import tiktoken\n",
    "import networkx as nx\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l1000_genes = []\n",
    "string_ids = []\n",
    "\n",
    "with open('../data/L1000_to_STRING.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        gene, string_id = line.rstrip().split('\\t')\n",
    "        l1000_genes.append(gene)\n",
    "        string_ids.append(string_id)\n",
    "\n",
    "\n",
    "string_interactions = {}\n",
    "\n",
    "# download: https://stringdb-static.org/download/protein.links.detailed.v11.5/9606.protein.links.detailed.v11.5.txt.gz\n",
    "with gzip.open('../data/9606.protein.links.detailed.v11.5.txt.gz', 'rt') as f:\n",
    "    # header\n",
    "    f.readline()\n",
    "    \n",
    "    # for fast search\n",
    "    _string_ids = set(string_ids)\n",
    "\n",
    "    for line in f:\n",
    "        columns = line.strip().split(' ')\n",
    "        if columns[0] in _string_ids and columns[1] in _string_ids:\n",
    "            string_interactions[(columns[0], columns[1])] = float(columns[-1])\n",
    "\n",
    "gene_to_stringId = dict(zip(l1000_genes, string_ids))\n",
    "\n",
    "\n",
    "biogrid_interactions = defaultdict(int)\n",
    "# download: https://downloads.thebiogrid.org/File/BioGRID/Release-Archive/BIOGRID-4.4.222/BIOGRID-ORGANISM-4.4.222.tab3.zip\n",
    "#           We created BIOGRID-ORGANISM-Homo_sapiens-4.4.221.tab to include just rows corresponding to Homo Sapiens\n",
    "with open('../data/BIOGRID-ORGANISM-Homo_sapiens-4.4.221.tab', 'r') as f:\n",
    "    # header\n",
    "    f.readline()\n",
    "\n",
    "    g1, g2 = 7, 8\n",
    "    for line in f:\n",
    "        line = line.split('\\t')\n",
    "        biogrid_interactions[(line[g1], line[g2])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "biogrid_graphg = nx.Graph()\n",
    "biogrid_graphg.add_edges_from(biogrid_interactions.keys())\n",
    "\n",
    "\n",
    "def compute(dataset, interaction_type='additive'):\n",
    "    df = pd.read_csv(f'../computed_interactions/{dataset}.csv')\n",
    "\n",
    "    if interaction_type == 'additive':\n",
    "        interaction_column = 'rmst_diff_f1+f2'\n",
    "    elif interaction_type == 'competing':\n",
    "        interaction_column = 'rmst_diff_f1-f2'\n",
    "    elif interaction_type == 'xor':\n",
    "        interaction_column = 'rmst_diff_f1*f2'\n",
    "    else:\n",
    "        raise ValueError('interaction_type must be one of: additive, competing, xor')\n",
    "    \n",
    "\n",
    "    results = []\n",
    "\n",
    "    df = df.sort_values(by=[interaction_column], ascending=False)\n",
    "    top_100 = df[:100]\n",
    "    for interaction_term, rmst_diff in zip(top_100['interaction'], df[interaction_column]):\n",
    "        gene1, gene2 = interaction_term.split('*')\n",
    "\n",
    "        stringId1 = gene_to_stringId[gene1]\n",
    "        stringId2 = gene_to_stringId[gene2]\n",
    "\n",
    "        paths = []\n",
    "        try:\n",
    "            paths = list(nx.all_shortest_paths(biogrid_graphg, gene1, gene2))\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "        min_path_length = min([len(path) for path in paths]) if paths else 0\n",
    "        \n",
    "        string_interaction_evidence = string_interactions.get((stringId1, stringId2), None)\n",
    "\n",
    "        biogrid_interaction_evidence = biogrid_interactions.get((gene1, gene2), 0) + biogrid_interactions.get((gene2, gene1), 0)\n",
    "\n",
    "        results.append((f'{gene1}*{gene2}', rmst_diff, string_interaction_evidence, biogrid_interaction_evidence, len(paths), min_path_length))\n",
    "    \n",
    "\n",
    "    save_path = f'../analyzed_interactions/{dataset}/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    df = pd.DataFrame(results, columns=['interaction', 'rmst_diff', 'string_interaction_evidence', 'biogrid_interaction_evidence', 'bioGRID_shortest_paths', 'bioGRID_min_path_length'])\n",
    "    df.to_csv(f'../analyzed_interactions/{dataset}/{interaction_type}.csv', index=False)\n",
    "\n",
    "\n",
    "DATASETS = [\n",
    "    \"METABRIC\",\n",
    "    \"BLCA\",\n",
    "    'BRCA',\n",
    "    \"CESC\",\n",
    "    \"COAD\",\n",
    "    \"GBM\",\n",
    "    \"HNSC\",\n",
    "    \"KIRC\",\n",
    "    \"KIRP\",\n",
    "    \"LAML\",\n",
    "    \"LGG\",\n",
    "    \"LIHC\",\n",
    "    \"LUAD\",\n",
    "    \"LUSC\",\n",
    "    \"OV\",\n",
    "    \"PRAD\",\n",
    "    \"READ\",\n",
    "    \"SKCM\",\n",
    "    \"STAD\",\n",
    "    \"THCA\",\n",
    "    \"UCEC\"\n",
    "]\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    compute(dataset, interaction_type='additive')\n",
    "    compute(dataset, interaction_type='competing')\n",
    "    compute(dataset, interaction_type='xor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "g = nx.Graph()\n",
    "g.add_edges_from(biogrid_interactions.keys())\n",
    "\n",
    "\n",
    "openai.organization = \"\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "def generate_prompt(cancer_type: str, gene1: str, gene2: str, paths: list, context: list):\n",
    "    promt = f\"\"\"\n",
    "    You are a helpful domain expert with a background in biology. You know the biology of each genes known in the literature. \n",
    "    \n",
    "    Cancer type: TCGA-{cancer_type}\n",
    "    Genes: {gene1} and {gene2}. \n",
    "\n",
    "    BioGRID protein interaction network; shortest path between {gene1} and {gene2}: {paths} .\n",
    "\n",
    "    Context: {context}\n",
    "\n",
    "    Based on what you know about these two genes and provided context. Describe briefly what specifically these genes do. \n",
    "    Can you reason about any possible functional associations between these two genes in specific biological terms? \n",
    "    Use context and your knowledge about biology to answer the question. Be specific in the processes where these genes are involved.\n",
    "\n",
    "    Be concise. Answer in 2-3 short sentences. Start with possible functional associations. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    return promt\n",
    "\n",
    "\n",
    "def compute(tcga_project, interaction_type='additive', llm='gpt-4', len_prompt=7600, paths_to_include=5):\n",
    "    df = pd.read_csv(f'../analyzed_interactions/{tcga_project}/{interaction_type}.csv')\n",
    "    uniprot_data = pd.read_csv(f'../data/uniprot_data/uniprot_data.csv')\n",
    "\n",
    "    pairs = set()\n",
    "    pairs.update(set( df.sort_values(by=['rmst_diff'], ascending=False)['interaction'][:10].values))\n",
    "    pairs.update(set(df.loc[df['string_interaction_evidence'].notnull()]['interaction'].values))\n",
    "    pairs.update(set(df.loc[df['biogrid_interaction_evidence'] > 0]['interaction'].values))\n",
    "    \n",
    "    results = []\n",
    "    for interaction in pairs:\n",
    "        gene1, gene2 = interaction.split('*')\n",
    "        # rmst_diff = df.loc[df['interaction'] == interaction]['rmst_diff'].values[0]\n",
    "\n",
    "\n",
    "        all_genes_in_all_paths = []\n",
    "        paths = []\n",
    "        try:\n",
    "            paths = list(nx.all_shortest_paths(g, gene1, gene2))\n",
    "        except:\n",
    "            pass\n",
    "        paths = paths[:paths_to_include]\n",
    "\n",
    "        for path in paths:\n",
    "            for gene in path[1:-1]:\n",
    "                if gene in uniprot_data['L1000_name']:\n",
    "                    gene_uniprot_data = uniprot_data.loc[uniprot_data['L1000_name'] == gene][['function_description', 'subunit_interactions']].values[0]\n",
    "                    gene_uniprot_data = ' '.join(gene_uniprot_data)\n",
    "                    all_genes_in_all_paths.append((gene, gene_uniprot_data))\n",
    "\n",
    "        gene1_uniprot_data = uniprot_data.loc[uniprot_data['L1000_name'] == gene1][['function_description', 'subunit_interactions']].values[0]\n",
    "        gene1_uniprot_data = ' '.join(gene1_uniprot_data)\n",
    "\n",
    "        gene2_uniprot_data = uniprot_data.loc[uniprot_data['L1000_name'] == gene2][['function_description', 'subunit_interactions']].values[0]\n",
    "        gene2_uniprot_data = ' '.join(gene2_uniprot_data)\n",
    "\n",
    "        prompt = generate_prompt(tcga_project, gene1, gene2, paths, [(gene1, gene1_uniprot_data), (gene2, gene2_uniprot_data),] + all_genes_in_all_paths)\n",
    "        enc = tiktoken.encoding_for_model(llm)\n",
    "        prompt = enc.decode(enc.encode(prompt)[:len_prompt])\n",
    "\n",
    "        retries = 3\n",
    "        for i in range(retries):\n",
    "            try:\n",
    "                response = openai.ChatCompletion.create(\n",
    "                        model=llm,\n",
    "                        messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "                openai_response = response.choices[0].message.content\n",
    "                break\n",
    "            except Exception as e:\n",
    "                if i < retries - 1:  # If not the last retry\n",
    "                    print('Model overloaded, retrying...')\n",
    "                    time.sleep(2)  # Wait for 2 seconds or you can increase this\n",
    "                    continue\n",
    "                else:\n",
    "                    print('Model overloaded, out of retries')\n",
    "                    openai_response = str(e)\n",
    "\n",
    "        # shortest_path_string = '|'.join(['-'.join(path) for path in paths]\n",
    "        results.append((interaction, openai_response.replace('\\n', ' ')))\n",
    "        time.sleep(0.1)\n",
    "\n",
    "\n",
    "    save_path = f'../analyzed_interactions/{tcga_project}/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    df = pd.DataFrame(results, columns=['interaction', 'summary'])\n",
    "    df.to_csv(f'../analyzed_interactions/{tcga_project}/{interaction_type}_{llm}_summary.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "DATASETS = [\n",
    "    \"METABRIC\",\n",
    "    \"BLCA\",\n",
    "    'BRCA',\n",
    "    \"CESC\",\n",
    "    \"COAD\",\n",
    "    \"GBM\",\n",
    "    \"HNSC\",\n",
    "    \"KIRC\",\n",
    "    \"KIRP\",\n",
    "    \"LAML\",\n",
    "    \"LGG\",\n",
    "    \"LIHC\",\n",
    "    \"LUAD\",\n",
    "    \"LUSC\",\n",
    "    \"OV\",\n",
    "    \"PRAD\",\n",
    "    \"READ\",\n",
    "    \"SKCM\",\n",
    "    \"STAD\",\n",
    "    \"THCA\",\n",
    "    \"UCEC\"\n",
    "]\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    compute(dataset, interaction_type='additive', llm='gpt-3.5-turbo', len_prompt=3600, paths_to_include=5)\n",
    "    compute(dataset, interaction_type='competing', llm='gpt-3.5-turbo', len_prompt=3600, paths_to_include=5)\n",
    "    compute(dataset, interaction_type='xor', llm='gpt-3.5-turbo', len_prompt=3600, paths_to_include=5)\n",
    "    compute(dataset, interaction_type='additive', paths_to_include=5)\n",
    "    compute(dataset, interaction_type='competing', paths_to_include=5)\n",
    "    compute(dataset, interaction_type='xor', paths_to_include=5)\n",
    "\n",
    "    print(dataset, 'done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_markdown_table(dataset: str, interaction_type: str, llm: str):\n",
    "    df = pd.read_csv(f'../analyzed_interactions/{dataset}/{interaction_type}.csv')\n",
    "    df_summary = pd.read_csv(f'../analyzed_interactions/{dataset}/{interaction_type}_{llm}_summary.csv')\n",
    "\n",
    "    save_path = f'../explained_interactions/{dataset}/'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(save_path)\n",
    "\n",
    "    with open(f'../explained_interactions/{dataset}/{interaction_type}_{llm}.md', 'w') as f:\n",
    "\n",
    "        header = \"\"\"| Genes&nbsp;&nbsp;&nbsp;&nbsp;| Data&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;| Summary |\"\"\"\n",
    "        header_divider = \"|:---|:---|:---|\"\n",
    "\n",
    "        f.write(f'{header}\\n{header_divider}\\n')\n",
    "\n",
    "        temp_store = []\n",
    "\n",
    "        for _, row in df_summary.iterrows():\n",
    "            interaction = row['interaction']\n",
    "            gene1, gene2 = interaction.split('*')\n",
    "            # gene1_link = f\"https://www.ncbi.nlm.nih.gov/gene?term={gene1}[Gene+Name]+AND+9606[Taxonomy+ID]\"\n",
    "            # gene2_link = f\"https://www.ncbi.nlm.nih.gov/gene?term={gene2}[Gene+Name]+AND+9606[Taxonomy+ID]\"\n",
    "\n",
    "            summary = row['summary']\n",
    "            # bioGRID_shortest_paths = row['bioGRID_shortest_paths']\n",
    "\n",
    "            rmst_diff = df.loc[df['interaction'] == interaction]['rmst_diff'].values[0]\n",
    "            string_score = df.loc[df['interaction'] == interaction]['string_interaction_evidence'].fillna(0).values[0]\n",
    "            biogrid_count = df.loc[df['interaction'] == interaction]['biogrid_interaction_evidence'].values[0]\n",
    "            biogrid_count = df.loc[df['interaction'] == interaction]['biogrid_interaction_evidence'].values[0]\n",
    "            bioGRID_shortest_paths = df.loc[df['interaction'] == interaction]['bioGRID_shortest_paths'].values[0]\n",
    "            bioGRID_min_path_length = df.loc[df['interaction'] == interaction]['bioGRID_min_path_length'].values[0]\n",
    "\n",
    "            row = f\"\"\"| [{gene1}](https://www.ncbi.nlm.nih.gov/gene?term={gene1}[Gene+Name]+AND+9606[Taxonomy+ID]) </br> and </br> [{gene2}](https://www.ncbi.nlm.nih.gov/gene?term={gene2}[Gene+Name]+AND+9606[Taxonomy+ID]) |  **RMST differance:** {round(rmst_diff, 1)}</br>**STRING score:** {int(string_score)}</br>**BioGRID count:** {biogrid_count}</br>**BioGRID shortest paths:** {bioGRID_shortest_paths} (min len {bioGRID_min_path_length}) | {summary}|\"\"\"\n",
    "            temp_store.append((rmst_diff, row))\n",
    "\n",
    "        temp_store.sort(key=lambda x: x[0], reverse=True)\n",
    "        for _, row in temp_store:\n",
    "            f.write(f'{row}\\n')\n",
    "\n",
    "\n",
    "\n",
    "DATASETS = [\n",
    "    \"METABRIC\",\n",
    "    \"BLCA\",\n",
    "    'BRCA',\n",
    "    \"CESC\",\n",
    "    \"COAD\",\n",
    "    \"GBM\",\n",
    "    \"HNSC\",\n",
    "    \"KIRC\",\n",
    "    \"KIRP\",\n",
    "    \"LAML\",\n",
    "    \"LGG\",\n",
    "    \"LIHC\",\n",
    "    \"LUAD\",\n",
    "    \"LUSC\",\n",
    "    \"OV\",\n",
    "    \"PRAD\",\n",
    "    \"READ\",\n",
    "    \"SKCM\",\n",
    "    \"STAD\",\n",
    "    \"THCA\",\n",
    "    \"UCEC\"\n",
    "]\n",
    "\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    create_markdown_table(dataset, interaction_type='additive', llm='gpt-3.5-turbo')\n",
    "    create_markdown_table(dataset, interaction_type='competing', llm='gpt-3.5-turbo')\n",
    "    create_markdown_table(dataset, interaction_type='xor', llm='gpt-3.5-turbo')\n",
    "\n",
    "    create_markdown_table(dataset, interaction_type='competing', llm='gpt-4')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "orange",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
